---
title: "Nextlfow"
author: "JR"
date: "11/10/2020"
output: html_document
---

Today we will install nextflow and install the Chip-seq pipeline. This way we can
run hundreds of ChIP-seq files simultaneously through, alignments, qc, peak calling
-- all the stuff you would ever want (even bigwig files for browsing raw data).

Nextflow has amazing documentation and a good place to start is here:

https://www.nextflow.io/docs/latest/getstarted.html

You can go over what is included in the pipeline (everything you need :) here:

https://nf-co.re/chipseq

Scroll down to the bottom of the link above and see that you will already get
a lot of results!


****************
Step 1 install:
****************

Next flow will install itself with this simple commmand below. However, you will
want to think about where to install it. When you know where you want it (usually
home directory or fairly high level up).

I installed nextflow in home directory so output error messages etc are always
located here:

/Users/jori2700/.nextflow/assets/nf-core/chipseq/main.nf

The main.nf will have all the code Nextflow's pipeline is running. If the pipeline
has an error it will send you to the line of code in main.nf that failed.

Alrighty, give it a go:

```{BASH}

wget -qO- https://get.nextflow.io | bash

```

Nice it's installed just like that! See what all you got in the .nextflow dir.

If you ever want to update nextflow just run the above. At the time of this doc
it is at: v20.10.0

Note that the install is in the "framework" dir and will keep older versions.
??? It's ok to remove them???

****************
Step 2: $PATH
****************

The path is a default place the computer will look for commands. Imagine you
had to tell Bash where list is?

you would have to type something like this

~/jori2700/.bash/ls to list files -- 

Instead of ls

So that path is an important aspect of unix/bash that you will never really hear
about until it becomes a bug :) Just to be safe let's add nextflow to our $PATH

```{BASH}

$PATH
# kinda hard to read with : seperated file
# we can make it easier to read with TRANSFORM (tr) a powerful bash command to
# repalce and find text. 
echo $PATH | tr ":" "\n"
# echo is just goint to print out the $PATH variable and pipe to transform to
#take the : and make it a new line (\n) --- ahhh so much nicer to read!

```

Now let's add to the $PATH 

!! Warning the order in the $PATH matters !! The computer will search for the
first usage of the command -- so if there are two commands with similar names 
be careful the first one will be used and may not be the intended program called.


We will use the script to tell the time as script in a new folder we are going to 
make -- that is NOT in our $PATH. Look throuhg the bash for tr, cut, but don't 
worry about the bash we are just using this to make a program in a folder and add
to our $PATH

Here is more on $PATH and where the code below was derived.

https://astrobiomike.github.io/unix/modifying_your_path


This is the example in the resource for $PATH mentioned above. It is an example of 
how to make a custom script, put it in path so you have a new command. It's quite basic, 
but we get to revisit some bash too :)! Let's make a quick command to tell the time.
Then put in our $PATH and be able to tell the time no matter which directory 
you are in :)

To start Run each of these lines in a row. 
```{BASH}

mkdir time_script
cd time_script

cat >> what-time-is-it.sh << 'EOF'
#!/bin/bash

current_time=$(date | tr -s " " "\t" | cut -f 4 | cut -d ":" -f 1,2)
#notice use of transmute (tr) and cut -- these are just grabbing the information
#bash date command output looks like: Sun Nov 15 18:06:10 MST 2020. Hint cut -f 4
# grabs the 4th item which is the time.

# Exercise see how transmute and cut grab the information more succinctly.

echo "The time is $current_time.
I'm glad to see you're making good use of it :)"

# this is just adding silly text to output with the time.

EOF

chmod +x what-time-is-it.sh

# chmod changes the permissions to a file, the +x gives it "executable" permission
# to go from shell to Kernel.

ls
cat what-time-is-it.sh

## Notice it wrote out the file what-time-is-it with the "cat >>" command.
```

Ok so we have a time telling script that only works in the current directory:

This is where I made it:

/Users/jori2700/CLASS/time_script

So now we can add this to $PATH and run the script whenever just like ls, cat etc.

First we are going to add the .sh script to our $PATH temporarily.

```{BASH}

pwd
#copy and paste path to the directoy the .sh script is in


export PATH="$PATH:/Users/Users/jori2700/CLASS/time_script"
what_time_is_it.sh #(notice we don't need the ./ now that the path is set)

```


Now how to permenantly add to you $PATH

```{BASH}

echo 'export PATH="$PATH:/Users/jori2700/CLASS/time_script/"' >> ~/.bash_profile
# nice let's take a look
echo $PATH | tr ":" "\n"
# we need to activate our new $PATH with
source ~/.bash_profile

cd anywhere
sh what-time-is-it.sh
```

Voila we can use the script anytime. Also this is a nice idea to have new scripts
etc in this folder as they will automatically be in $PATH now. To run a .sh file
you want to type "sh filename" in this case sh waht-time-is-it.

Let's add nextflow to our $PATH

```{BASH}

cd ~/
ls -lah
cd .nextflow
pwd
#/Users/jori2700/.nextflow
ecd
source ~/.bash_profile #or start a new session.
```

Alright we have next flow installed and we never have to worry about fiji finding
the commands again!


****************
Step 4: Install Chip-seeker pipeline
****************

nextflow pull nf-core/chipseq

-r 1.2.1


## TODO ## for some reason i am still running older nextflow is it because I added 
to my path and then updated after?

## Also can't see to update chip-seq pipeline -- should we use the same as before?


## Bash ps command to print all current processes running abit cumbersume can 
pipe to grep.

tail -f to follow process updates


****************
Step 4: Config_FILE
****************

Ok so we have next flow and the Chip seeker pipeline and our server. We need to 
have them to talk to and instruct eachother on how best to proceed.

To this end we need to make a nextflow.config file. Here next flow will look for the:

executor : here we see it is slurm (as we will describe more below). It stands
for Simple Linux Utility for Resource Management. Basically a simple job scheduler.

queue : there is a long and short queue, they describe themselves that one queue
is short or faster, and the other is longer. 

memory : your telling fiji or your server, computer etc how much RAM or memory to
use for the process. This is something to think about and consult with your IT team.
You don't want to over load the server or your computer!

maxforks : this tells nextflow how many processes can be run in parallel. Let's 
say you had 40 fastq files to run through a pipeline you can speed up the process
of running 40 tasks in parallel!

Here is all this put together in a simple few lines that schedules how nextflow
will communicate with your machine and how to move forward with it's core processes.


process {
  executor='slurm'
  queue='short'
  memory='32 GB'
  maxForks=40
}



****************
Step 3: SLURM - run.sh
****************

The config file above allows root communication for job instrucitons. However, 
we still need to talk to our server or computer directly to allocate computer or 
server resources, where all the files nextflow needs and much more. So we need 
to run a script on our server to invoke next flow, give it the configurations
and start running. 

Here is an example of how we will invoke nextflow using BASH on our server.

```{BASH}

#!/bin/bash
#SBATCH -p long
#SBATCH --job-name=Hepg2_Pol_test
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=john.rinn@colorado.edu
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --mem=6gb
#SBATCH --time=100:00:00
#SBATCH --output=nextflow.out
#SBATCH --error=nextflow.err


### Here we are setting up all the details of the run. Nextflow will go to the 
# congfig file first and then, use those instructions to establish shell to run
# the above commands. These are slurm instructions and nextflow learned it would 
# be in slurm via the config file. The .out and .err files are estabished and we 
# will be looking at these a lot. 

## The other noteable is the "WALL CLOCK" 

pwd; hostname; date
echo "Here we go again $SLURM_CPUS_ON_NODE core."

module load singularity/3.1.1

nextflow run nf-core/chipseq -r 1.1.0 \
-profile singularity \
--single_end \
--input pol_run_design.csv \
--fasta /Shares/rinn_class/data/genomes/human/gencode/v32/GRCh38.p13.genome.fa \
--gtf /Shares/rinn_class/data/genomes/human/gencode/v32/gencode.v32.annotation.gtf \
--macs_gsize 2.7e9 \
--blacklist hg38-blacklist.v2.bed \
--email john.rinn@colorado.edu \
-resume \
-c nextflow.config

date

```






****************
Step 3:Checking on proceesses 
****************


sqeue -identikey

TODO other ways of checking on sbatch processes .... killing processess 



****************
Step 4: Design file
****************

group,replicate,fastq_1,fastq_2,antibody,control
POLR2A,1,/Shares/rinn_class/data/CLASS_2021/CLASS_2021/data/fastq/ENCFF000XWJ.fastq.gz,,POLR2A,ENCSR000EEN
POLR2A,2,../fastq/ENCFF000PNT.fastq.gz,,POLR2A,ENCSR000BLH
POLR2A,3,../fastq/ENCFF000XWR.fastq.gz,,POLR2A,ENCSR000EEN
POLR2A,1,../fastq/ENCFF000XWJ.fastq.gz,,POLR2A,ENCSR000EEN
POLR2A,2,../fastq/ENCFF000PNT.fastq.gz,,POLR2A,ENCSR000EEN
POLR2A,3,../fastq/ENCFF000XWR.fastq.gz,,POLR2A,ENCSR000EEN
POLR2A,1,../fastq/ENCFF000XWJ.fastq.gz,,POLR2A,ENCSR000BLH
POLR2A,2,../fastq/ENCFF000PNT.fastq.gz,,POLR2A,ENCSR000BLH
POLR2A,3,../fastq/ENCFF000XWR.fastq.gz,,POLR2A,ENCSR000BLH
ENCSR000EEN,1,../fastq/ENCFF000XTF.fastq.gz,,,
ENCSR000BLH,1,../fastq/ENCFF000POO.fastq.gz,,,



